{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import csv, json\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, TimeDistributed, Bidirectional, LSTM, Dense, Lambda, concatenate, Dropout, BatchNormalization, Convolution1D, Merge, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PAIRS_FILE = 'data/train.csv'\n",
    "GLOVE_FILE = 'data/glove.840B.300d.txt'\n",
    "Q1_TRAINING_DATA_FILE = 'data/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'data/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'data/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'data/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'data/nb_words.json'\n",
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "SAFE_DIV = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: 404290\n"
     ]
    }
   ],
   "source": [
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "with open(QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        question1.append(preprocess(row['question1']))\n",
    "        question2.append(preprocess(row['question2']))\n",
    "        is_duplicate.append(row['is_duplicate'])\n",
    "print('Question pairs: %d' % len(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 91458\n"
     ]
    }
   ],
   "source": [
    "questions = question1 + question2\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(questions)\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 2196016\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings: %d' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 24937\n"
     ]
    }
   ],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data tensor: (404290, 25)\n",
      "Shape of question2 data tensor: (404290, 25)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "q1_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(is_duplicate, dtype=int)\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
    "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
    "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
    "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
    "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
    "    json.dump({'nb_words': nb_words}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Variables\n",
    "MODEL_WEIGHTS_FILE = 'question_pairs_weights_lstm.h5'\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "filter_length = 3 # Length of filter for Convolution1D\n",
    "SENT_EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question3 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question4 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "q1 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q1)\n",
    "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "q2 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q2)\n",
    "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "\n",
    "q3 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question3)\n",
    "\n",
    "q3 = Bidirectional(LSTM(SENT_EMBEDDING_DIM, return_sequences=True), merge_mode=\"sum\")(q3)\n",
    "q3 = Flatten()(q3)\n",
    "#q3 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q3)\n",
    "\n",
    "q4 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question4)\n",
    "q4 =Bidirectional(LSTM(SENT_EMBEDDING_DIM, return_sequences=True), merge_mode=\"sum\")(q4)\n",
    "q4 = Flatten()(q4)\n",
    "\n",
    "merged = concatenate([q1,q2,q3,q4])\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2,question3,question4], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 300)      27437700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 25, 300)      27437700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 25, 300)      27437700    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 25, 300)      27437700    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 25, 300)      90300       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 25, 300)      90300       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 25, 128)      439296      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 25, 128)      439296      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 300)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 300)          0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3200)         0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3200)         0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7000)         0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          1400200     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200)          800         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          40200       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            201         batch_normalization_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 112,334,193\n",
      "Trainable params: 2,581,793\n",
      "Non-trainable params: 109,752,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2018-05-02 15:58:40.909171\n",
      "Train on 327474 samples, validate on 36387 samples\n",
      "Epoch 1/25\n",
      " - 1421s - loss: 0.5301 - acc: 0.7333 - val_loss: 0.4758 - val_acc: 0.7657\n",
      "Epoch 2/25\n",
      " - 1403s - loss: 0.4574 - acc: 0.7793 - val_loss: 0.4357 - val_acc: 0.7898\n",
      "Epoch 3/25\n",
      " - 1396s - loss: 0.4107 - acc: 0.8084 - val_loss: 0.4224 - val_acc: 0.7999\n",
      "Epoch 4/25\n",
      " - 1396s - loss: 0.3610 - acc: 0.8364 - val_loss: 0.4073 - val_acc: 0.8079\n",
      "Epoch 5/25\n",
      " - 1395s - loss: 0.3117 - acc: 0.8647 - val_loss: 0.4142 - val_acc: 0.8109\n",
      "Epoch 6/25\n",
      " - 1395s - loss: 0.2636 - acc: 0.8894 - val_loss: 0.4151 - val_acc: 0.8134\n",
      "Epoch 7/25\n",
      " - 1396s - loss: 0.2252 - acc: 0.9073 - val_loss: 0.4247 - val_acc: 0.8112\n",
      "Epoch 8/25\n",
      " - 1396s - loss: 0.1951 - acc: 0.9217 - val_loss: 0.4536 - val_acc: 0.8119\n",
      "Epoch 9/25\n",
      " - 1395s - loss: 0.1718 - acc: 0.9318 - val_loss: 0.4534 - val_acc: 0.8134\n",
      "Epoch 10/25\n",
      " - 1396s - loss: 0.1572 - acc: 0.9379 - val_loss: 0.4863 - val_acc: 0.8151\n",
      "Epoch 11/25\n",
      " - 1397s - loss: 0.1464 - acc: 0.9430 - val_loss: 0.4989 - val_acc: 0.8064\n",
      "Epoch 12/25\n",
      " - 1396s - loss: 0.1361 - acc: 0.9469 - val_loss: 0.4819 - val_acc: 0.8132\n",
      "Epoch 13/25\n",
      " - 1396s - loss: 0.1254 - acc: 0.9519 - val_loss: 0.5114 - val_acc: 0.8127\n",
      "Epoch 14/25\n",
      " - 1397s - loss: 0.1196 - acc: 0.9543 - val_loss: 0.5163 - val_acc: 0.8095\n",
      "Epoch 15/25\n",
      " - 1396s - loss: 0.1156 - acc: 0.9559 - val_loss: 0.5106 - val_acc: 0.8125\n",
      "Epoch 16/25\n",
      " - 1398s - loss: 0.1048 - acc: 0.9603 - val_loss: 0.5222 - val_acc: 0.8146\n",
      "Epoch 17/25\n",
      " - 1396s - loss: 0.1024 - acc: 0.9618 - val_loss: 0.5490 - val_acc: 0.8126\n",
      "Epoch 18/25\n",
      " - 1397s - loss: 0.0939 - acc: 0.9650 - val_loss: 0.5847 - val_acc: 0.8169\n",
      "Epoch 19/25\n",
      " - 1396s - loss: 0.0913 - acc: 0.9658 - val_loss: 0.5487 - val_acc: 0.8158\n",
      "Epoch 20/25\n",
      " - 1397s - loss: 0.0869 - acc: 0.9678 - val_loss: 0.5650 - val_acc: 0.8143\n",
      "Epoch 21/25\n",
      " - 1398s - loss: 0.0838 - acc: 0.9689 - val_loss: 0.5683 - val_acc: 0.8144\n",
      "Epoch 22/25\n",
      " - 1398s - loss: 0.0817 - acc: 0.9695 - val_loss: 0.5717 - val_acc: 0.8100\n",
      "Epoch 23/25\n",
      " - 1398s - loss: 0.0789 - acc: 0.9707 - val_loss: 0.5484 - val_acc: 0.8153\n",
      "Epoch 24/25\n",
      " - 1398s - loss: 0.0759 - acc: 0.9724 - val_loss: 0.5856 - val_acc: 0.8190\n",
      "Epoch 25/25\n",
      " - 1398s - loss: 0.0731 - acc: 0.9729 - val_loss: 0.5916 - val_acc: 0.8175\n",
      "Training ended at 2018-05-03 01:41:56.499314\n",
      "Minutes elapsed: 583.259833\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([Q1_train, Q2_train,Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    verbose=2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  training  validation\n",
      "0       1  0.733344    0.765713\n",
      "1       2  0.779268    0.789815\n",
      "2       3  0.808431    0.799901\n",
      "3       4  0.836375    0.807871\n",
      "4       5  0.864685    0.810921\n",
      "5       6  0.889417    0.813367\n",
      "6       7  0.907324    0.811169\n",
      "7       8  0.921743    0.811911\n",
      "8       9  0.931805    0.813422\n",
      "9      10  0.937940    0.815126\n",
      "10     11  0.942951    0.806359\n",
      "11     12  0.946912    0.813175\n",
      "12     13  0.951947    0.812708\n",
      "13     14  0.954262    0.809465\n",
      "14     15  0.955920    0.812488\n",
      "15     16  0.960259    0.814577\n",
      "16     17  0.961829    0.812570\n",
      "17     18  0.964977    0.816858\n",
      "18     19  0.965787    0.815841\n",
      "19     20  0.967756    0.814274\n",
      "20     21  0.968947    0.814412\n",
      "21     22  0.969524    0.809987\n",
      "22     23  0.970703    0.815264\n",
      "23     24  0.972447    0.819029\n",
      "24     25  0.972941    0.817462\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['acc'],\n",
    "                    'validation': history.history['val_acc']})\n",
    "print(acc)\n",
    "ax = acc.iloc[:,:].plot(x='epoch',  grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy at epoch 24 = 0.8190\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))\n",
    "model.load_weights(MODEL_WEIGHTS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.5869, accuracy = 0.8170\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([Q1_test, Q2_test,Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
