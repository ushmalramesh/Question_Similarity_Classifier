{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import csv, json\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, TimeDistributed, Dense, Lambda, LSTM, concatenate, Dropout, BatchNormalization, Convolution1D, Merge, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_PAIRS_FILE = 'data/train.csv'\n",
    "GLOVE_FILE = 'data/glove.840B.300d.txt'\n",
    "Q1_TRAINING_DATA_FILE = 'data/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'data/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'data/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'data/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'data/nb_words.json'\n",
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = ['ourselves', 'hers', 'between', 'yourself', 'but', 'again', 'there', 'about', 'once', 'during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself', 'other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i', 'after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
    "SAFE_DIV = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \"m\").replace(\",000\", \"k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: 404290\n"
     ]
    }
   ],
   "source": [
    "question1 = []\n",
    "question2 = []\n",
    "is_duplicate = []\n",
    "with open(QUESTION_PAIRS_FILE, encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        question1.append(preprocess(row['question1']))\n",
    "        question2.append(preprocess(row['question2']))\n",
    "        is_duplicate.append(row['is_duplicate'])\n",
    "print('Question pairs: %d' % len(question1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 91458\n"
     ]
    }
   ],
   "source": [
    "questions = question1 + question2\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(questions)\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 2196016\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(GLOVE_FILE, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings: %d' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 24937\n"
     ]
    }
   ],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(word_embedding_matrix, axis=1) == 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data tensor: (404290, 25)\n",
      "Shape of question2 data tensor: (404290, 25)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "q1_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(is_duplicate, dtype=int)\n",
    "print('Shape of question1 data tensor:', q1_data.shape)\n",
    "print('Shape of question2 data tensor:', q2_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(Q1_TRAINING_DATA_FILE, 'wb'), q1_data)\n",
    "np.save(open(Q2_TRAINING_DATA_FILE, 'wb'), q2_data)\n",
    "np.save(open(LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
    "np.save(open(WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
    "with open(NB_WORDS_DATA_FILE, 'w') as f:\n",
    "    json.dump({'nb_words': nb_words}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Variables\n",
    "MODEL_WEIGHTS_FILE = 'question_pairs_weights_lstm_base.h5'\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "nb_filter = 32 # Number of filters to use in Convolution1D\n",
    "filter_length = 3 # Length of filter for Convolution1D\n",
    "SENT_EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1_train 363861\n",
      "Q2_train 363861\n",
      "Q1_test 40429\n",
      "Q2_test 40429\n"
     ]
    }
   ],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n",
    "print(\"Q1_train\" , len(Q1_train))\n",
    "print(\"Q2_train\" , len(Q2_train))\n",
    "print(\"Q1_test\" , len(Q1_test))\n",
    "print(\"Q2_test\" , len(Q2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "\n",
    "q1 = LSTM(SENT_EMBEDDING_DIM)(q1)\n",
    "#q1 = Flatten()(q1)\n",
    "#q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "q2 = LSTM(SENT_EMBEDDING_DIM)(q2)\n",
    "#q2 = Flatten()(q2)\n",
    "#q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "merged = concatenate([q1,q2])\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 300)      27437700    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 25, 300)      27437700    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          219648      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          219648      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            257         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 55,314,953\n",
      "Trainable params: 439,553\n",
      "Non-trainable params: 54,875,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2018-05-07 02:52:45.488050\n",
      "Train on 327474 samples, validate on 36387 samples\n",
      "Epoch 1/25\n",
      " - 676s - loss: 0.5227 - acc: 0.7404 - val_loss: 0.4897 - val_acc: 0.7636\n",
      "Epoch 2/25\n",
      " - 669s - loss: 0.4597 - acc: 0.7826 - val_loss: 0.4683 - val_acc: 0.7776\n",
      "Epoch 3/25\n",
      " - 670s - loss: 0.4043 - acc: 0.8154 - val_loss: 0.4684 - val_acc: 0.7846\n",
      "Epoch 4/25\n",
      " - 671s - loss: 0.3471 - acc: 0.8473 - val_loss: 0.4861 - val_acc: 0.7801\n",
      "Epoch 5/25\n",
      " - 667s - loss: 0.2940 - acc: 0.8730 - val_loss: 0.5157 - val_acc: 0.7836\n",
      "Epoch 6/25\n",
      " - 667s - loss: 0.2459 - acc: 0.8966 - val_loss: 0.5682 - val_acc: 0.7794\n",
      "Epoch 7/25\n",
      " - 665s - loss: 0.2076 - acc: 0.9145 - val_loss: 0.6187 - val_acc: 0.7762\n",
      "Epoch 8/25\n",
      " - 666s - loss: 0.1777 - acc: 0.9279 - val_loss: 0.6765 - val_acc: 0.7740\n",
      "Epoch 9/25\n",
      " - 665s - loss: 0.1545 - acc: 0.9381 - val_loss: 0.7293 - val_acc: 0.7759\n",
      "Epoch 10/25\n",
      " - 665s - loss: 0.1373 - acc: 0.9458 - val_loss: 0.7878 - val_acc: 0.7729\n",
      "Epoch 11/25\n",
      " - 665s - loss: 0.1268 - acc: 0.9498 - val_loss: 0.8220 - val_acc: 0.7735\n",
      "Epoch 12/25\n",
      " - 667s - loss: 0.1178 - acc: 0.9541 - val_loss: 0.8623 - val_acc: 0.7786\n",
      "Epoch 13/25\n",
      " - 669s - loss: 0.1112 - acc: 0.9568 - val_loss: 0.8986 - val_acc: 0.7762\n",
      "Epoch 14/25\n",
      " - 669s - loss: 0.1051 - acc: 0.9593 - val_loss: 0.9240 - val_acc: 0.7772\n",
      "Epoch 15/25\n",
      " - 669s - loss: 0.0999 - acc: 0.9618 - val_loss: 0.9539 - val_acc: 0.7723\n",
      "Epoch 16/25\n",
      " - 668s - loss: 0.0964 - acc: 0.9630 - val_loss: 0.9717 - val_acc: 0.7724\n",
      "Epoch 17/25\n",
      " - 665s - loss: 0.0939 - acc: 0.9637 - val_loss: 0.9784 - val_acc: 0.7787\n",
      "Epoch 18/25\n",
      " - 663s - loss: 0.0911 - acc: 0.9648 - val_loss: 1.0006 - val_acc: 0.7734\n",
      "Epoch 19/25\n",
      " - 666s - loss: 0.0894 - acc: 0.9659 - val_loss: 1.0151 - val_acc: 0.7760\n",
      "Epoch 20/25\n",
      " - 666s - loss: 0.0871 - acc: 0.9669 - val_loss: 1.0267 - val_acc: 0.7784\n",
      "Epoch 21/25\n",
      " - 666s - loss: 0.0860 - acc: 0.9671 - val_loss: 1.0364 - val_acc: 0.7750\n",
      "Epoch 22/25\n",
      " - 669s - loss: 0.0844 - acc: 0.9681 - val_loss: 1.0519 - val_acc: 0.7770\n",
      "Epoch 23/25\n",
      " - 669s - loss: 0.0834 - acc: 0.9683 - val_loss: 1.0692 - val_acc: 0.7747\n",
      "Epoch 24/25\n",
      " - 669s - loss: 0.0810 - acc: 0.9691 - val_loss: 1.0618 - val_acc: 0.7743\n",
      "Epoch 25/25\n",
      " - 670s - loss: 0.0805 - acc: 0.9695 - val_loss: 1.0812 - val_acc: 0.7787\n",
      "Training ended at 2018-05-07 07:31:01.763083\n",
      "Minutes elapsed: 278.271247\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    verbose=2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  training  validation\n",
      "0       1  0.740379    0.763569\n",
      "1       2  0.782581    0.777558\n",
      "2       3  0.815359    0.784648\n",
      "3       4  0.847286    0.780114\n",
      "4       5  0.873004    0.783604\n",
      "5       6  0.896648    0.779399\n",
      "6       7  0.914485    0.776184\n",
      "7       8  0.927942    0.773958\n",
      "8       9  0.938136    0.775854\n",
      "9      10  0.945809    0.772886\n",
      "10     11  0.949785    0.773518\n",
      "11     12  0.954091    0.778575\n",
      "12     13  0.956763    0.776211\n",
      "13     14  0.959346    0.777173\n",
      "14     15  0.961765    0.772254\n",
      "15     16  0.962956    0.772391\n",
      "16     17  0.963750    0.778657\n",
      "17     18  0.964819    0.773436\n",
      "18     19  0.965854    0.776046\n",
      "19     20  0.966932    0.778382\n",
      "20     21  0.967078    0.775002\n",
      "21     22  0.968095    0.776981\n",
      "22     23  0.968285    0.774700\n",
      "23     24  0.969133    0.774288\n",
      "24     25  0.969543    0.778712\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['acc'],\n",
    "                    'validation': history.history['val_acc']})\n",
    "print(acc)\n",
    "ax = acc.iloc[:,:].plot(x='epoch',  grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy at epoch 3 = 0.7846\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))\n",
    "model.load_weights(MODEL_WEIGHTS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4714, accuracy = 0.7826\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
